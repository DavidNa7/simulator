{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import copy\n",
    "import scipy as sp\n",
    "import math\n",
    "import seaborn\n",
    "import pickle\n",
    "import warnings\n",
    "import matplotlib\n",
    "import re\n",
    "import multiprocessing\n",
    "\n",
    "from lib.mobilitysim import MobilitySimulator\n",
    "from lib.dynamics import DiseaseModel\n",
    "from lib.inference import * \n",
    "from bayes_opt import BayesianOptimization\n",
    "from lib.parallel import *\n",
    "from lib.distributions import CovidDistributions\n",
    "from lib.plot import Plotter\n",
    "from lib.data import collect_data_from_df\n",
    "from lib.measures import (\n",
    "    MeasureList, \n",
    "    BetaMultiplierMeasure, \n",
    "    BetaMultiplierMeasureByType,\n",
    "    SocialDistancingForAllMeasure, \n",
    "    SocialDistancingByAgeMeasure,\n",
    "    SocialDistancingForPositiveMeasure, \n",
    "    Interval)\n",
    "\n",
    "from lib.mobilitysim import MobilitySimulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Determine settings for inference. Nothing below should have to be changed signficiantly/at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings used to generate mobility traces on the fly. These settings are used for inference\n",
    "# See town-generator.ipynb for an example on how to create\n",
    "mob_settings = 'lib/tu_settings_20_10.pk'\n",
    "case_downsample = 10\n",
    "\n",
    "# parameter bounds\n",
    "param_bounds = {\n",
    "    'beta' : {\n",
    "        'household' : [0.0, 10.0],\n",
    "        'education' : [0.0, 10.0],\n",
    "        'office' : [0.0, 10.0],\n",
    "        'social' : [0.0, 10.0],\n",
    "        'supermarket' : [0.0, 10.0],\n",
    "        'transport' : [0.0, 10.0],\n",
    "    },\n",
    "    'mu' : [0.0, 1.0]\n",
    "}\n",
    "\n",
    "# Based on population size, approx. 300 tests/day in Area of Tübingen (~135 in city of Tübingen)\n",
    "tests_per_day = 10\n",
    "\n",
    "# seed for random states and log file\n",
    "c = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Covid19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data last updated at:  13.04.2020, 00:00 Uhr\n",
      "Data last updated at:  13.04.2020, 00:00 Uhr\n",
      "Data last updated at:  13.04.2020, 00:00 Uhr\n"
     ]
    }
   ],
   "source": [
    "new_cases_ = collect_data_from_df('LK Tübingen', 'new')\n",
    "resistant_cases_ = collect_data_from_df('LK Tübingen', 'recovered')\n",
    "fatality_cases_ = collect_data_from_df('LK Tübingen', 'fatality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirical fatality rate per age group from the above data. RKI data defines 6 groups: **0-4y, 5-14y, 15-34y, 35-59y, 60-79y, 80+y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical fatality rates per age group:   [0.0, 0.0, 0.0, 0.0025252525252525255, 0.005952380952380952, 0.17647058823529413]\n"
     ]
    }
   ],
   "source": [
    "# fatality rate per age group\n",
    "num_age_groups = fatality_cases_.shape[1] \n",
    "fatality_rates_by_age = (fatality_cases_[-1, :] / \\\n",
    "    (new_cases_[-1, :] +  fatality_cases_[-1, :] + resistant_cases_[-1, :]))\n",
    "\n",
    "print('Empirical fatality rates per age group:  ', fatality_rates_by_age.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale down cases based on number of people in simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cases, resistant_cases, fatality_cases = (\n",
    "    1/case_downsample * new_cases_, \n",
    "    1/case_downsample * resistant_cases_, \n",
    "    1/case_downsample * fatality_cases_)\n",
    "new_cases, resistant_cases, fatality_cases = np.ceil(new_cases), np.ceil(resistant_cases), np.ceil(fatality_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum time fixed by real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max time T (days): 17\n",
      "Age groups:        6\n",
      "Positive at t=0:   3\n",
      "Positive at t=T:   57\n"
     ]
    }
   ],
   "source": [
    "max_time = int(new_cases.shape[0] * 24.0) # maximum time to simulate, in hours\n",
    "\n",
    "print('Max time T (days):', new_cases.shape[0])\n",
    "print('Age groups:       ', new_cases.shape[1])\n",
    "print('Positive at t=0:  ', int(new_cases[0, :].sum()))\n",
    "print('Positive at t=T:  ', int(new_cases[-1, :].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate correct distributions\n",
    "distributions = CovidDistributions(fatality_rates_by_age=fatality_rates_by_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial seed count (based on infection counts on March 10)\n",
    "initial_seeds = {\n",
    "    'expo' : 10,\n",
    "    'ipre' : 1,\n",
    "    'isym' : 3,\n",
    "    'iasy' : 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add here \"isolate positive at home\"\n"
     ]
    }
   ],
   "source": [
    "# standard quarantine of positive tests and test availablility\n",
    "measure_list = MeasureList([\n",
    "    SocialDistancingForPositiveMeasure(\n",
    "        t_window=Interval(0.0, max_time), p_stay_home=1.0)\n",
    "])\n",
    "print('Add here \"isolate positive at home\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set testing parameters\n",
    "testing_params = {\n",
    "    'testing_t_window'    : [0.0, max_time], # in hours\n",
    "    'testing_frequency'   : 24.0,     # in hours\n",
    "    'test_reporting_lag'  : 48.0,     # in hours (actual and self-report delay)\n",
    "    'tests_per_batch'     : tests_per_day, # assume 300 tests/day in LK Tübingen\n",
    "    'test_smart_delta'    : 24.0 * 3, # in hours\n",
    "    'test_smart_duration' : 24.0 * 7, # in hours\n",
    "    'test_smart_action'   : 'isolate', \n",
    "    'test_smart_num_contacts'   : 10, \n",
    "    'test_targets'        : 'isym',\n",
    "    'test_queue_policy'   : 'fifo',\n",
    "    'smart_tracing'       : None, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load settings as set in header of this notebook and generate example traces to extract information for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Advanced loop\\n\\n*** to write\\n\\nMulti-task GP paper implemented https://papers.nips.cc/paper/3189-multi-task-gaussian-process-prediction.pdf\\n(for correlated output dimension, which is the case for us)\\n\\ndrive home difference between objective and noisy observation\\n\\nadd mu xi beta as optimized params\\n\\n\\n*** to do\\n\\n- don't forget to standardize\\n- account for test lag (make sure start of T positive of model is shifted by `test_lag` of test params in loss)\\n- make sure the compositionality is properly handled \\n    (see botorch paper, do need specific objective functionk `GenericCObjective`)\\n- make sure heteroskedastic GP is fitted \\n    (using provided empirical SEM errors, and if so also mention in write-up)\\n    \\n    \\n-  covariates are normalized to the unit cube and outcomes are standardized (zero mean, unit variance).\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Advanced loop\n",
    "\n",
    "*** to write\n",
    "\n",
    "Multi-task GP paper implemented https://papers.nips.cc/paper/3189-multi-task-gaussian-process-prediction.pdf\n",
    "(for correlated output dimension, which is the case for us)\n",
    "\n",
    "drive home difference between objective and noisy observation\n",
    "\n",
    "add mu xi beta as optimized params\n",
    "\n",
    "\n",
    "*** to do\n",
    "\n",
    "- don't forget to standardize\n",
    "- account for test lag (make sure start of T positive of model is shifted by `test_lag` of test params in loss)\n",
    "- make sure the compositionality is properly handled \n",
    "    (see botorch paper, do need specific objective functionk `GenericCObjective`)\n",
    "- make sure heteroskedastic GP is fitted \n",
    "    (using provided empirical SEM errors, and if so also mention in write-up)\n",
    "    \n",
    "    \n",
    "-  covariates are normalized to the unit cube and outcomes are standardized (zero mean, unit variance).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gpytorch, torch, botorch, sobol_seq\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.models import FixedNoiseGP, ModelListGP, HeteroskedasticSingleTaskGP\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood, MarginalLogLikelihood\n",
    "from botorch.acquisition.monte_carlo import MCAcquisitionFunction, qNoisyExpectedImprovement, qSimpleRegret\n",
    "from botorch.acquisition.objective import MCAcquisitionObjective\n",
    "from botorch.acquisition.max_value_entropy_search import qMaxValueEntropy\n",
    "from botorch.acquisition import OneShotAcquisitionFunction\n",
    "import botorch.utils.transforms as transforms\n",
    "from botorch.utils.transforms import match_batch_shape, t_batch_mode_transform\n",
    "\n",
    "# from botorch.acquisition import qKnowledgeGradient\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler, IIDNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition.objective import GenericMCObjective, ConstrainedMCObjective\n",
    "from botorch.gen import get_best_candidates, gen_candidates_torch\n",
    "from botorch.optim import gen_batch_initial_conditions\n",
    "\n",
    "import time, pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "torch.set_printoptions(precision=4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_one_shot_kg_initial_conditions(\n",
    "    acq_function,\n",
    "    bounds,\n",
    "    q,\n",
    "    num_restarts,\n",
    "    raw_samples,\n",
    "    options=None,\n",
    "):\n",
    "    r\"\"\"Generate a batch of smart initializations for qKnowledgeGradient.\n",
    "    This function generates initial conditions for optimizing one-shot KG using\n",
    "    the maximizer of the posterior objective. Intutively, the maximizer of the\n",
    "    fantasized posterior will often be close to a maximizer of the current\n",
    "    posterior. This function uses that fact to generate the initital conditions\n",
    "    for the fantasy points. Specifically, a fraction of `1 - frac_random` (see\n",
    "    options) is generated by sampling from the set of maximizers of the\n",
    "    posterior objective (obtained via random restart optimization) according to\n",
    "    a softmax transformation of their respective values. This means that this\n",
    "    initialization strategy internally solves an acquisition function\n",
    "    maximization problem. The remaining `frac_random` fantasy points as well as\n",
    "    all `q` candidate points are chosen according to the standard initialization\n",
    "    strategy in `gen_batch_initial_conditions`.\n",
    "    Args:\n",
    "        acq_function: The qKnowledgeGradient instance to be optimized.\n",
    "        bounds: A `2 x d` tensor of lower and upper bounds for each column of\n",
    "            task features.\n",
    "        q: The number of candidates to consider.\n",
    "        num_restarts: The number of starting points for multistart acquisition\n",
    "            function optimization.\n",
    "        raw_samples: The number of raw samples to consider in the initialization\n",
    "            heuristic.\n",
    "        options: Options for initial condition generation. These contain all\n",
    "            settings for the standard heuristic initialization from\n",
    "            `gen_batch_initial_conditions`. In addition, they contain\n",
    "            `frac_random` (the fraction of fully random fantasy points),\n",
    "            `num_inner_restarts` and `raw_inner_samples` (the number of random\n",
    "            restarts and raw samples for solving the posterior objective\n",
    "            maximization problem, respectively) and `eta` (temperature parameter\n",
    "            for sampling heuristic from posterior objective maximizers).\n",
    "    Returns:\n",
    "        A `num_restarts x q' x d` tensor that can be used as initial conditions\n",
    "        for `optimize_acqf()`. Here `q' = q + num_fantasies` is the total number\n",
    "        of points (candidate points plus fantasy points).\n",
    "    Example:\n",
    "        >>> qKG = qKnowledgeGradient(model, num_fantasies=64)\n",
    "        >>> bounds = torch.tensor([[0., 0.], [1., 1.]])\n",
    "        >>> Xinit = gen_one_shot_kg_initial_conditions(\n",
    "        >>>     qKG, bounds, q=3, num_restarts=10, raw_samples=512,\n",
    "        >>>     options={\"frac_random\": 0.25},\n",
    "        >>> )\n",
    "    \"\"\"\n",
    "    options = options or {}\n",
    "    frac_random: float = options.get(\"frac_random\", 0.1)\n",
    "    if not 0 < frac_random < 1:\n",
    "        raise ValueError(\n",
    "            f\"frac_random must take on values in (0,1). Value: {frac_random}\"\n",
    "        )\n",
    "    q_aug = acq_function.get_augmented_q_batch_size(q=q)\n",
    "\n",
    "    # TODO: Avoid unnecessary computation by not generating all candidates\n",
    "    ics = gen_batch_initial_conditions(\n",
    "        acq_function=acq_function,\n",
    "        bounds=bounds,\n",
    "        q=q_aug,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,\n",
    "        options=options,\n",
    "    )\n",
    "\n",
    "    # compute maximizer of the value function\n",
    "    value_function = _get_value_function(\n",
    "        model=acq_function.model,\n",
    "        objective=acq_function.objective,\n",
    "        sampler=acq_function.inner_sampler,\n",
    "    )\n",
    "#     from .optimize import optimize_acqf\n",
    "\n",
    "    fantasy_cands, fantasy_vals = optimize_acqf(\n",
    "        acq_function=value_function,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=options.get(\"num_inner_restarts\", 20),\n",
    "        raw_samples=options.get(\"raw_inner_samples\", 1024),\n",
    "        return_best_only=False,\n",
    "    )\n",
    "\n",
    "    # sampling from the optimizers\n",
    "    n_value = int((1 - frac_random) * (q_aug - q))  # number of non-random ICs\n",
    "    eta = options.get(\"eta\", 2.0)\n",
    "    weights = torch.exp(eta * transforms.standardize(fantasy_vals))\n",
    "    idx = torch.multinomial(weights, num_restarts * n_value, replacement=True)\n",
    "\n",
    "    # set the respective initial conditions to the sampled optimizers\n",
    "    ics[..., -n_value:, :] = fantasy_cands[idx, 0].view(num_restarts, n_value, -1)\n",
    "    return ics\n",
    "\n",
    "def _split_fantasy_points(X, n_f):\n",
    "    r\"\"\"Split a one-shot optimization input into actual and fantasy points\n",
    "\n",
    "    Args:\n",
    "        X: A `batch_shape x (q + n_f) x d`-dim tensor of actual and fantasy\n",
    "            points\n",
    "\n",
    "    Returns:\n",
    "        2-element tuple containing\n",
    "\n",
    "        - A `batch_shape x q x d`-dim tensor `X_actual` of input candidates.\n",
    "        - A `n_f x batch_shape x 1 x d`-dim tensor `X_fantasies` of fantasy\n",
    "            points, where `X_fantasies[i, batch_idx]` is the i-th fantasy point\n",
    "            associated with the batch indexed by `batch_idx`.\n",
    "    \"\"\"\n",
    "#     print('_split_fantasy_points  ', X.shape) # this is [5, 1, 7] but should actually get [5, (1 + 64), 7]\n",
    "    \n",
    "    if n_f > X.size(-2):\n",
    "        raise ValueError(\n",
    "            f\"n_f ({n_f}) must be less than the q-batch dimension of X ({X.size(-2)})\"\n",
    "        )\n",
    "    split_sizes = [X.size(-2) - n_f, n_f]\n",
    "    X_actual, X_fantasies = torch.split(X, split_sizes, dim=-2)\n",
    "    # X_fantasies is b x num_fantasies x d, needs to be num_fantasies x b x 1 x d\n",
    "    # for batch mode evaluation with batch shape num_fantasies x b.\n",
    "    # b x num_fantasies x d --> num_fantasies x b x d\n",
    "    X_fantasies = X_fantasies.permute(-2, *range(X_fantasies.dim() - 2), -1)\n",
    "    # num_fantasies x b x 1 x d\n",
    "    X_fantasies = X_fantasies.unsqueeze(dim=-2)\n",
    "    return X_actual, X_fantasies\n",
    "\n",
    "\n",
    "def _get_value_function(\n",
    "    model,\n",
    "    objective=None,\n",
    "    sampler=None,\n",
    "):\n",
    "    r\"\"\"Construct value function (i.e. inner acquisition function).\"\"\"\n",
    "    if isinstance(objective, MCAcquisitionObjective):\n",
    "        return qSimpleRegret(model=model, sampler=sampler, objective=objective)\n",
    "    else:\n",
    "        return PosteriorMean(model=model, objective=objective)\n",
    "\n",
    "\n",
    "# class OwnKnowledgeGradient(MCAcquisitionFunction, OneShotAcquisitionFunction):\n",
    "class qKnowledgeGradient(MCAcquisitionFunction, OneShotAcquisitionFunction):\n",
    "    r\"\"\"\n",
    "    Copy of qKnowledgeGradient on\n",
    "    https://github.com/pytorch/botorch/blob/master/botorch/acquisition/knowledge_gradient.py\n",
    "    \n",
    "    with a bug fixed that disables using the original qKnowledgeGradient class\n",
    "    \n",
    "    =======\n",
    "    \n",
    "    Batch Knowledge Gradient using one-shot optimization.\n",
    "\n",
    "    This computes the batch Knowledge Gradient using fantasies for the outer\n",
    "    expectation and either the model posterior mean or MC-sampling for the inner\n",
    "    expectation.\n",
    "\n",
    "    In addition to the design variables, the input `X` also includes variables\n",
    "    for the optimal designs for each of the fantasy models. For a fixed number\n",
    "    of fantasies, all parts of `X` can be optimized in a \"one-shot\" fashion.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_fantasies=64,\n",
    "        sampler=None,\n",
    "        objective=None,\n",
    "        inner_sampler=None,\n",
    "        X_pending=None,\n",
    "        current_value=None,\n",
    "    ):\n",
    "        r\"\"\"q-Knowledge Gradient (one-shot optimization).\n",
    "\n",
    "        Args:\n",
    "            model: A fitted model. Must support fantasizing.\n",
    "            num_fantasies: The number of fantasy points to use. More fantasy\n",
    "                points result in a better approximation, at the expense of\n",
    "                memory and wall time. Unused if `sampler` is specified.\n",
    "            sampler: The sampler used to sample fantasy observations. Optional\n",
    "                if `num_fantasies` is specified.\n",
    "            objective: The objective under which the samples are evaluated. If\n",
    "                `None` or a ScalarizedObjective, then the analytic posterior mean\n",
    "                is used, otherwise the objective is MC-evaluated (using\n",
    "                inner_sampler).\n",
    "            inner_sampler: The sampler used for inner sampling. Ignored if the\n",
    "                objective is `None` or a ScalarizedObjective.\n",
    "            X_pending: A `m x d`-dim Tensor of `m` design points that have\n",
    "                points that have been submitted for function evaluation\n",
    "                but have not yet been evaluated.\n",
    "            current_value: The current value, i.e. the expected best objective\n",
    "                given the observed points `D`. If omitted, forward will not\n",
    "                return the actual KG value, but the expected best objective\n",
    "                given the data set `D u X`.\n",
    "        \"\"\"\n",
    "        if sampler is None:\n",
    "            if num_fantasies is None:\n",
    "                raise ValueError(\n",
    "                    \"Must specify `num_fantasies` if no `sampler` is provided.\"\n",
    "                )\n",
    "            # base samples should be fixed for joint optimization over X, X_fantasies\n",
    "            sampler = SobolQMCNormalSampler(\n",
    "                num_samples=num_fantasies, resample=False, collapse_batch_dims=True\n",
    "            )\n",
    "        elif num_fantasies is not None:\n",
    "            if sampler.sample_shape != torch.Size([num_fantasies]):\n",
    "                raise ValueError(\n",
    "                    f\"The sampler shape must match num_fantasies={num_fantasies}.\"\n",
    "                )\n",
    "        else:\n",
    "            num_fantasies = sampler.sample_shape[0]\n",
    "        super(MCAcquisitionFunction, self).__init__(model=model)\n",
    "        # if not explicitly specified, we use the posterior mean for linear objs\n",
    "        if isinstance(objective, MCAcquisitionObjective) and inner_sampler is None:\n",
    "            inner_sampler = SobolQMCNormalSampler(\n",
    "                num_samples=128, resample=False, collapse_batch_dims=True\n",
    "            )\n",
    "        if objective is None and model.num_outputs != 1:\n",
    "            raise UnsupportedError(\n",
    "                \"Must specify an objective when using a multi-output model.\"\n",
    "            )\n",
    "        self.sampler = sampler\n",
    "        self.objective = objective\n",
    "        self.set_X_pending(X_pending)\n",
    "        self.inner_sampler = inner_sampler\n",
    "        self.num_fantasies = num_fantasies\n",
    "        self.current_value = current_value\n",
    "\n",
    "    @t_batch_mode_transform()\n",
    "    def forward(self, X):\n",
    "        r\"\"\"Evaluate qKnowledgeGradient on the candidate set `X`.\n",
    "\n",
    "        Args:\n",
    "            X: A `b x (q + num_fantasies) x d` Tensor with `b` t-batches of\n",
    "                `q + num_fantasies` design points each. We split this X tensor\n",
    "                into two parts in the `q` dimension (`dim=-2`). The first `q`\n",
    "                are the q-batch of design points and the last num_fantasies are\n",
    "                the current solutions of the inner optimization problem.\n",
    "\n",
    "                `X_fantasies = X[..., -num_fantasies:, :]`\n",
    "                `X_fantasies.shape = b x num_fantasies x d`\n",
    "\n",
    "                `X_actual = X[..., :-num_fantasies, :]`\n",
    "                `X_actual.shape = b x q x d`\n",
    "\n",
    "        Returns:\n",
    "            A Tensor of shape `b`. For t-batch b, the q-KG value of the design\n",
    "                `X_actual[b]` is averaged across the fantasy models, where\n",
    "                `X_fantasies[b, i]` is chosen as the final selection for the\n",
    "                `i`-th fantasy model.\n",
    "                NOTE: If `current_value` is not provided, then this is not the\n",
    "                true KG value of `X_actual[b]`, and `X_fantasies[b, : ]` must be\n",
    "                maximized at fixed `X_actual[b]`.\n",
    "        \"\"\"\n",
    "#         print('forward', X.shape) #torch.Size([5, 1, 7])\n",
    "        X_actual, X_fantasies = _split_fantasy_points(X=X, n_f=self.num_fantasies)\n",
    "\n",
    "        # We only concatenate X_pending into the X part after splitting\n",
    "        if self.X_pending is not None:\n",
    "            X_actual = torch.cat(\n",
    "                [X_actual, match_batch_shape(self.X_pending, X_actual)], dim=-2\n",
    "            )\n",
    "\n",
    "        # construct the fantasy model of shape `num_fantasies x b`\n",
    "        fantasy_model = self.model.fantasize(\n",
    "            X=X_actual, sampler=self.sampler, observation_noise=True\n",
    "        )\n",
    "\n",
    "        # get the value function\n",
    "        value_function = _get_value_function(\n",
    "            model=fantasy_model, objective=self.objective, sampler=self.inner_sampler\n",
    "        )\n",
    "\n",
    "        # make sure to propagate gradients to the fantasy model train inputs\n",
    "        with botorch.settings.propagate_grads(True):\n",
    "            values = value_function(X=X_fantasies)  # num_fantasies x b\n",
    "\n",
    "        if self.current_value is not None:\n",
    "            values = values - self.current_value\n",
    "\n",
    "        # return average over the fantasy samples\n",
    "        return values.mean(dim=0)\n",
    "\n",
    "    def get_augmented_q_batch_size(self, q):\n",
    "        r\"\"\"Get augmented q batch size for one-shot optimzation.\n",
    "\n",
    "        Args:\n",
    "            q: The number of candidates to consider jointly.\n",
    "\n",
    "        Returns:\n",
    "            The augmented size for one-shot optimzation (including variables\n",
    "            parameterizing the fantasy solutions).\n",
    "        \"\"\"\n",
    "        return q + self.num_fantasies\n",
    "\n",
    "    def extract_candidates(self, X_full):\n",
    "        r\"\"\"We only return X as the set of candidates post-optimization.\n",
    "\n",
    "        Args:\n",
    "            X_full: A `b x (q + num_fantasies) x d`-dim Tensor with `b`\n",
    "                t-batches of `q + num_fantasies` design points each.\n",
    "\n",
    "        Returns:\n",
    "            A `b x q x d`-dim Tensor with `b` t-batches of `q` design points each.\n",
    "        \"\"\"\n",
    "        return X_full[..., : -self.num_fantasies, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     14
    ]
   },
   "outputs": [],
   "source": [
    "def pdict_to_parr(d, bound_dict=True):\n",
    "\n",
    "    list(param_bounds['beta'].keys()) + ['mu']\n",
    "    arr = torch.stack([\n",
    "        torch.tensor(d['beta']['household']),\n",
    "        torch.tensor(d['beta']['education']),\n",
    "        torch.tensor(d['beta']['office']),\n",
    "        torch.tensor(d['beta']['social']),\n",
    "        torch.tensor(d['beta']['supermarket']),\n",
    "        torch.tensor(d['beta']['transport']),\n",
    "        torch.tensor(d['mu']),\n",
    "    ])\n",
    "    return arr\n",
    "\n",
    "def parr_to_pdict(arr, bound_dict=True):\n",
    "    \n",
    "    d = {\n",
    "        'beta': {\n",
    "            'household': arr[0],\n",
    "            'education': arr[1],\n",
    "            'office': arr[2],\n",
    "            'social': arr[3],\n",
    "            'supermarket': arr[4],\n",
    "            'transport': arr[5],\n",
    "        },\n",
    "        'mu': arr[6]\n",
    "    }\n",
    "    return d\n",
    "\n",
    "example = {\n",
    "    'beta': {\n",
    "        'household': torch.tensor([3.]),\n",
    "        'education': torch.tensor([0.5]),\n",
    "        'office': torch.tensor([10.]),\n",
    "        'social': torch.tensor([7.]),\n",
    "        'supermarket': torch.tensor([4.]),\n",
    "        'transport': torch.tensor([2.])\n",
    "    },\n",
    "      'mu': torch.tensor([0.5000])}\n",
    "\n",
    "assert(example == parr_to_pdict(pdict_to_parr(example)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation bounds:\n",
      "{'beta': {'education': tensor([ 0., 10.]),\n",
      "          'household': tensor([ 0., 10.]),\n",
      "          'office': tensor([ 0., 10.]),\n",
      "          'social': tensor([ 0., 10.]),\n",
      "          'supermarket': tensor([ 0., 10.]),\n",
      "          'transport': tensor([ 0., 10.])},\n",
      " 'mu': tensor([0., 1.])}\n",
      "\n",
      "BO bounds (converted):\n",
      "{'beta': {'education': tensor([0., 1.]),\n",
      "          'household': tensor([0., 1.]),\n",
      "          'office': tensor([0., 1.]),\n",
      "          'social': tensor([0., 1.]),\n",
      "          'supermarket': tensor([0., 1.]),\n",
      "          'transport': tensor([0., 1.])},\n",
      " 'mu': tensor([0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "N_DAYS, N_AGE = new_cases.shape\n",
    "G_obs = torch.tensor(new_cases).reshape(N_DAYS * N_AGE) # flattened\n",
    "N_PARAMS = 7\n",
    "\n",
    "SIM_BOUNDS = pdict_to_parr(param_bounds)\n",
    "BO_BOUNDS = torch.stack([torch.zeros(N_PARAMS), torch.ones(N_PARAMS)]).T\n",
    "\n",
    "print('Simulation bounds:')\n",
    "pprint.pprint(parr_to_pdict(SIM_BOUNDS))\n",
    "print('\\nBO bounds (converted):')\n",
    "pprint.pprint(parr_to_pdict(BO_BOUNDS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# simulation\n",
    "def composite_simulation(norm_params):\n",
    "        \n",
    "    # un-normalize normalized params to obtain simulation parameters\n",
    "    params = transforms.unnormalize(norm_params, SIM_BOUNDS.T)\n",
    " \n",
    "    # run simulation\n",
    "    \n",
    "    # get results\n",
    "    out = params.sum() * torch.ones((N_DAYS, N_AGE))\n",
    "    \n",
    "    # flatten\n",
    "    means = out.reshape(1, N_DAYS * N_AGE)  \n",
    "    \n",
    "    # standard error of mean\n",
    "    SEM = 0.1 * torch.rand_like(means)\n",
    "    \n",
    "    return means, SEM\n",
    "\n",
    "# objective\n",
    "def composite_squared_loss(G):\n",
    "    \n",
    "#     print('composite_squared_loss', G.shape, G_obs.shape)\n",
    "    \n",
    "#     return - (G - G_obs).pow(2).sum(dim=-1)\n",
    "    return - (G).pow(2).sum(dim=-1)\n",
    "   \n",
    "\n",
    "composite_squared_objective = GenericMCObjective(composite_squared_loss)\n",
    "\n",
    "# select objective\n",
    "objective = composite_squared_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "def standardize(Y, only_stddev) :\n",
    "    r\"\"\"Standardizes (zero mean, unit variance) a n x m tensor by dim=0.\n",
    "    Returns standardized 'y' and std.dev. of 'y'\n",
    "    \"\"\"\n",
    "    stddim = -1 if Y.dim() < 2 else -2\n",
    "    Y_std = Y.std(dim=stddim, keepdim=True)\n",
    "    Y_std = Y_std.where(Y_std >= 1e-9, torch.full_like(Y_std, 1.0))\n",
    "    if only_stddev:\n",
    "        return Y_std\n",
    "    else:\n",
    "        return (Y - Y.mean(dim=stddim, keepdim=True)) / Y_std\n",
    "\n",
    "\n",
    "def generate_initial_data(n):\n",
    "    if n <= 0:\n",
    "        raise ValueError('qKnowledgeGradient and GP needs at least one observation to be defined properly.')\n",
    "    \n",
    "    # sobol sequence\n",
    "    # new_thetas: [n, N_PARAMS]\n",
    "    new_thetas = torch.tensor(sobol_seq.i4_sobol_generate(N_PARAMS, n), dtype=torch.float)\n",
    "    \n",
    "    # new_G, new_G_sem: [n, N_DAYS * N_AGE]\n",
    "    new_G = torch.zeros((n, N_DAYS * N_AGE), dtype=torch.float)\n",
    "    new_G_sem = torch.zeros((n, N_DAYS * N_AGE), dtype=torch.float)\n",
    "    for i in range(n):\n",
    "        print(f'Simulating inital setting {i+1}/{n} ... ', end='')\n",
    "        # mean and standard error of mean (sem) of every simulation output\n",
    "        G, G_sem = composite_simulation(new_thetas[i, :])\n",
    "        new_G[i, :] = G\n",
    "        new_G_sem[i, :] = G_sem\n",
    "        print('done.')\n",
    "            \n",
    "    # compute best objective from simulations\n",
    "    best_f = objective(new_G).max().item()\n",
    "    \n",
    "    return new_thetas, new_G, new_G_sem, best_f\n",
    "    \n",
    "def initialize_model(train_x, train_y, train_y_sem):\n",
    "\n",
    "    # standardize (zero mean, unit variance)\n",
    "    # 1) get standard deviation (i.e. multiplier when standardized)\n",
    "    Y_stddev = standardize(train_y, only_stddev=True)\n",
    "    \n",
    "    # 2_ standardize y to make GP hyperparameter tuning work out\n",
    "    train_y = standardize(train_y, only_stddev=False)\n",
    "    \n",
    "    # 3) scale standard error of mean `train_y_sem` by the same amount as train_y in `standardize`\n",
    "    #    since Var[aX] = a^2 Var[X], we have SEM(aX) = a SEM(X)\n",
    "    train_y_sem /= Y_stddev\n",
    "    train_ynoise = train_y_sem.pow(2.0) # noise is in variance units\n",
    "    \n",
    "    # train \n",
    "    model = FixedNoiseGP(train_x, train_y, train_ynoise)\n",
    "    \n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        \n",
    "    return mll, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def optimize_acqf_and_get_observation(acq_func, num_restarts, raw_samples, batch_limit, maxiter):\n",
    "    \"\"\"\n",
    "    Optimizes the acquisition function, and returns a new candidate and a noisy observation.\n",
    "    botorch defaults:  num_restarts=10, raw_samples=256, batch_limit=5, maxiter=200\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_initial_conditions = gen_one_shot_kg_initial_conditions(\n",
    "        acq_function=acq_func,\n",
    "        bounds=BO_BOUNDS.T,\n",
    "        q=1,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,\n",
    "        options={\"batch_limit\": batch_limit, \"maxiter\": maxiter},\n",
    "    )\n",
    "    \n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=BO_BOUNDS.T,\n",
    "        q=1,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": batch_limit, \"maxiter\": maxiter},\n",
    "        batch_initial_conditions=batch_initial_conditions\n",
    "    )\n",
    "        \n",
    "    # proposed evaluation \n",
    "    new_theta = candidates.detach()\n",
    "    \n",
    "    # observe new noisy function evaluation\n",
    "    new_G, new_G_sem = composite_simulation(new_theta)\n",
    "\n",
    "    return new_theta, new_G, new_G_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating inital setting 1/5 ... done.\n",
      "Simulating inital setting 2/5 ... done.\n",
      "Simulating inital setting 3/5 ... done.\n",
      "Simulating inital setting 4/5 ... done.\n",
      "Simulating inital setting 5/5 ... done.\n",
      "Best objective (init phase):  -93336.375\n",
      " 1: best = -93336.38, -143454.34, tensor([[0.1878, 0.3637, 0.7734, 0.7658, 0.9368, 0.6866, 0.3608]]), time = 29.06.\n",
      " 2: best = -93336.38, -139006.23, tensor([[0.3768, 0.2303, 1.0000, 0.8424, 0.8443, 0.3661, 0.3186]]), time = 26.03.\n",
      " 3: best = -93336.38, -130109.94, tensor([[0.2066, 0.9520, 0.4193, 0.8840, 0.3722, 0.6384, 0.9888]]), time = 35.19.\n",
      " 4: best = -93336.38, -100325.67, tensor([[0.6246, 0.7884, 0.3191, 0.2098, 0.9623, 0.2003, 0.3170]]), time = 38.67.\n",
      " 5: best = -53942.82, -53942.82, tensor([[0.1807, 0.4933, 0.8484, 0.4128, 0.0192, 0.2649, 0.8029]]), time = 36.17.\n",
      " 6: best = -53942.82, -145032.45, tensor([[0.8783, 0.1140, 0.4989, 0.9240, 0.5166, 0.8363, 0.0270]]), time = 35.36.\n",
      " 7: best = -53942.82, -137149.12, tensor([[0.5455, 0.4948, 0.3458, 0.8631, 0.6020, 0.7842, 0.3151]]), time = 35.49.\n",
      " 8: best = -53942.82, -66239.88, tensor([[0.5144, 0.4927, 0.4345, 0.5426, 0.3373, 0.2030, 0.2385]]), time = 35.40.\n"
     ]
    }
   ],
   "source": [
    "INIT_SAMPLES = 5 # initial random evaluation points\n",
    "N_BATCH = 100 # rounds of BO after the initial random batch\n",
    "MC_SAMPLES = 256 # samples for MC acquisition function \n",
    "verbose = True\n",
    "\n",
    "# Knowledge gradient\n",
    "num_fantasies = 64\n",
    "num_restarts = 10\n",
    "raw_samples = 256\n",
    "batch_limit = 5\n",
    "maxiter = 20\n",
    "\n",
    "best_observed = []\n",
    "\n",
    "# generate initial training data and initialize model\n",
    "train_theta, train_G, train_G_sem, best_observed_y = generate_initial_data(n=INIT_SAMPLES)\n",
    "mll, model = initialize_model(train_theta, train_G, train_G_sem)\n",
    "\n",
    "print('Best objective (init phase): ', best_observed_y)\n",
    "\n",
    "best_observed.append(best_observed_y)\n",
    "\n",
    "# run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "for tt in range(1, N_BATCH + 1):\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # fit the GP model\n",
    "    fit_gpytorch_model(mll)\n",
    "    \n",
    "    # acquisition function\n",
    "    acqf = qKnowledgeGradient(\n",
    "        model=model,\n",
    "        objective=objective,\n",
    "        num_fantasies=num_fantasies,\n",
    "    )\n",
    "    \n",
    "    # optimize and get new observation\n",
    "    new_theta, new_G, new_G_sem = optimize_acqf_and_get_observation(\n",
    "        acqf, num_restarts=num_restarts, raw_samples=raw_samples, \n",
    "        batch_limit=batch_limit, maxiter=maxiter)\n",
    "    \n",
    "    train_theta = torch.cat([train_theta, new_theta], dim=0) # [tt, N_PARAMS]\n",
    "    train_G = torch.cat([train_G, new_G], dim=0) # [tt, N_DAYS * N_AGE]\n",
    "    train_G_sem = torch.cat([train_G_sem, new_G_sem], dim=0) # [tt, N_DAYS * N_AGE]\n",
    "    \n",
    "    # update progress\n",
    "    best_observed_y = objective(train_G).max().item()\n",
    "    best_observed.append(best_observed_y)\n",
    "    \n",
    "    # re-initialize the models so they are ready for fitting on next iteration\n",
    "    mll, model = initialize_model(\n",
    "        train_theta, \n",
    "        train_G, \n",
    "        train_G_sem,\n",
    "    )\n",
    "\n",
    "    t1 = time.time()\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"{tt:>2}: best = \"\n",
    "            f\"{best_observed_y:>4.2f}, \"\n",
    "            f\"{objective(new_G).item():>4.2f}, \"\n",
    "            f\"{new_theta.detach()}, \"\n",
    "            f\"time = {t1 - t0:>4.2f}.\"\n",
    "            , end=\"\\n\"\n",
    "        )\n",
    "    else:\n",
    "        print(\".\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
